#!/usr/bin/env python3
"""
PostgreSQLå‘é‡å­˜å‚¨è¿ç§»æµ‹è¯•è„šæœ¬
"""

import asyncio
import logging
import sys
from pathlib import Path
from typing import List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from config import settings
from postgres_vector_store import create_postgres_vector_store_builder
from services.rag_service import RAGService
from llama_index.core import Document
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_postgres_connection():
    """æµ‹è¯•PostgreSQLè¿æ¥"""
    logger.info("Testing PostgreSQL connection...")
    
    try:
        import psycopg2
        
        # æµ‹è¯•è¿æ¥
        conn = psycopg2.connect(
            host=settings.POSTGRES_HOST,
            port=settings.POSTGRES_PORT,
            database=settings.POSTGRES_DATABASE,
            user=settings.POSTGRES_USER,
            password=settings.POSTGRES_PASSWORD
        )
        
        cursor = conn.cursor()
        cursor.execute("SELECT version();")
        version = cursor.fetchone()[0]
        logger.info(f"PostgreSQL connection successful: {version}")
        
        cursor.close()
        conn.close()
        
        return True
        
    except Exception as e:
        logger.error(f"PostgreSQL connection failed: {e}")
        return False

def test_postgres_vector_store():
    """æµ‹è¯•PostgreSQLå‘é‡å­˜å‚¨åˆ›å»º"""
    logger.info("Testing PostgreSQL vector store creation...")
    
    try:
        # åˆ›å»ºæµ‹è¯•å‘é‡å­˜å‚¨æ„å»ºå™¨
        builder = create_postgres_vector_store_builder(
            table_name="test_vector_store"
        )
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = builder.get_stats()
        logger.info(f"Vector store stats: {stats}")
        
        # åˆ›å»ºå‘é‡å­˜å‚¨
        vector_store = builder.create_vector_store()
        logger.info("PostgreSQL vector store created successfully")
        
        return True
        
    except Exception as e:
        logger.error(f"PostgreSQL vector store creation failed: {e}")
        return False

def test_embedding_model():
    """æµ‹è¯•åµŒå…¥æ¨¡å‹"""
    logger.info("Testing embedding model...")
    
    try:
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        embed_model = HuggingFaceEmbedding(
            model_name=settings.EMBED_MODEL_PATH,
            device=settings.GPU_DEVICE if settings.USE_GPU else "cpu",
            trust_remote_code=True
        )
        
        # æµ‹è¯•åµŒå…¥
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
        embedding = embed_model.get_text_embedding(test_text)
        
        logger.info(f"Embedding dimension: {len(embedding)}")
        logger.info("Embedding model test successful")
        
        return embed_model
        
    except Exception as e:
        logger.error(f"Embedding model test failed: {e}")
        return None

def test_document_indexing():
    """æµ‹è¯•æ–‡æ¡£ç´¢å¼•åˆ›å»º"""
    logger.info("Testing document indexing with PostgreSQL...")
    
    try:
        # æµ‹è¯•åµŒå…¥æ¨¡å‹
        embed_model = test_embedding_model()
        if embed_model is None:
            return False
        
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        test_documents = [
            Document(text="è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼ŒåŒ…å«ä¸€äº›ä¸­æ–‡å†…å®¹ã€‚", metadata={"source": "test1.txt"}),
            Document(text="This is the second test document with English content.", metadata={"source": "test2.txt"}),
            Document(text="è¿™æ˜¯ç¬¬ä¸‰ä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºéªŒè¯å‘é‡å­˜å‚¨åŠŸèƒ½ã€‚", metadata={"source": "test3.txt"})
        ]
        
        # åˆ›å»ºPostgreSQLå‘é‡å­˜å‚¨æ„å»ºå™¨
        builder = create_postgres_vector_store_builder(
            table_name="test_migration_index"
        )
        
        # åˆ é™¤ç°æœ‰è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        builder.delete_index()
        
        # ä»æ–‡æ¡£åˆ›å»ºç´¢å¼•
        from llama_index.core.node_parser import SentenceSplitter
        
        # åˆ†å‰²æ–‡æ¡£ä¸ºèŠ‚ç‚¹
        splitter = SentenceSplitter(
            chunk_size=settings.CHUNK_SIZE,
            chunk_overlap=settings.CHUNK_OVERLAP
        )
        
        nodes = splitter.get_nodes_from_documents(test_documents)
        logger.info(f"Created {len(nodes)} nodes from {len(test_documents)} documents")
        
        # åˆ›å»ºç´¢å¼•
        index = builder.create_index_from_nodes(nodes, embed_model)
        logger.info("Document indexing successful")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = builder.get_stats()
        logger.info(f"Index stats: {stats}")
        
        return True
        
    except Exception as e:
        logger.error(f"Document indexing failed: {e}")
        return False

async def test_rag_service():
    """æµ‹è¯•RAGæœåŠ¡"""
    logger.info("Testing RAG service with PostgreSQL...")
    
    try:
        # åˆ›å»ºRAGæœåŠ¡
        rag_service = RAGService()
        
        # æµ‹è¯•åŠ è½½ç´¢å¼•
        index_id = "test_migration_index"
        success = await rag_service.load_index(index_id)
        
        if not success:
            logger.error(f"Failed to load index: {index_id}")
            return False
        
        # æµ‹è¯•æ£€ç´¢
        query = "æµ‹è¯•æ–‡æ¡£"
        results = await rag_service.hybrid_retrieve(index_id, query, top_k=3)
        
        logger.info(f"Retrieved {len(results)} results for query: '{query}'")
        for i, result in enumerate(results):
            logger.info(f"Result {i+1}: {result.node.text[:100]}... (score: {result.score})")
        
        logger.info("RAG service test successful")
        return True
        
    except Exception as e:
        logger.error(f"RAG service test failed: {e}")
        return False

def cleanup_test_data():
    """æ¸…ç†æµ‹è¯•æ•°æ®"""
    logger.info("Cleaning up test data...")
    
    try:
        # åˆ é™¤æµ‹è¯•è¡¨
        builder = create_postgres_vector_store_builder(
            table_name="test_vector_store"
        )
        builder.delete_index()
        
        builder = create_postgres_vector_store_builder(
            table_name="test_migration_index"
        )
        builder.delete_index()
        
        logger.info("Test data cleanup successful")
        
    except Exception as e:
        logger.error(f"Test data cleanup failed: {e}")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("Starting PostgreSQL migration tests...")
    
    # æ˜¾ç¤ºå½“å‰é…ç½®
    logger.info(f"Vector store type: {settings.VECTOR_STORE_TYPE}")
    logger.info(f"PostgreSQL host: {settings.POSTGRES_HOST}")
    logger.info(f"PostgreSQL database: {settings.POSTGRES_DATABASE}")
    
    tests = [
        ("PostgreSQL Connection", test_postgres_connection),
        ("PostgreSQL Vector Store", test_postgres_vector_store),
        ("Document Indexing", test_document_indexing),
        ("RAG Service", test_rag_service)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        logger.info(f"\n{'='*50}")
        logger.info(f"Running test: {test_name}")
        logger.info(f"{'='*50}")
        
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            
            if result:
                logger.info(f"âœ… {test_name} PASSED")
                passed += 1
            else:
                logger.error(f"âŒ {test_name} FAILED")
                
        except Exception as e:
            logger.error(f"âŒ {test_name} FAILED with exception: {e}")
    
    # æ¸…ç†æµ‹è¯•æ•°æ®
    cleanup_test_data()
    
    # æ˜¾ç¤ºç»“æœ
    logger.info(f"\n{'='*50}")
    logger.info(f"Test Results: {passed}/{total} tests passed")
    logger.info(f"Success rate: {passed/total*100:.1f}%")
    logger.info(f"{'='*50}")
    
    if passed == total:
        logger.info("ğŸ‰ All tests passed! PostgreSQL migration is ready.")
    else:
        logger.warning("âš ï¸  Some tests failed. Please check the logs and fix issues.")
    
    return passed == total

if __name__ == "__main__":
    asyncio.run(main())