"""create_vector_store_tasks_table

Revision ID: 494a5726f88d
Revises: 418796245a49
Create Date: 2025-06-09 11:45:48.414762

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '494a5726f88d'
down_revision: Union[str, None] = '418796245a49'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    # Create tables that should exist
    op.create_table('user_sessions',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('token_jti', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('expires_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('is_revoked', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='user_sessions_pkey')
    )
    op.create_index('ix_user_sessions_user_id', 'user_sessions', ['user_id'], unique=False)
    op.create_index('ix_user_sessions_token_jti', 'user_sessions', ['token_jti'], unique=True)
    
    op.create_table('parse_tasks',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('task_id', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('file_path', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('file_name', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('file_size', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('file_extension', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('mime_type', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('parser_type', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('progress', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('current_stage', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('stage_details', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('started_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('completed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('result', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('error', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('processing_logs', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('output_directory', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('output_files', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('config', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='parse_tasks_pkey'),
    postgresql_ignore_search_path=False
    )
    op.create_index('ix_parse_tasks_task_id', 'parse_tasks', ['task_id'], unique=True)
    
    op.create_table('vector_store_tasks',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('task_id', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('parse_task_id', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('progress', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('started_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('completed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('result', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('error', sa.TEXT(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['parse_task_id'], ['parse_tasks.task_id'], name='vector_store_tasks_parse_task_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='vector_store_tasks_pkey'),
    postgresql_ignore_search_path=False
    )
    op.create_index('ix_vector_store_tasks_task_id', 'vector_store_tasks', ['task_id'], unique=True)
    op.create_index('ix_vector_store_tasks_parse_task_id', 'vector_store_tasks', ['parse_task_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    # Drop tables that were created in upgrade with existence checks
    from sqlalchemy import inspect
    conn = op.get_bind()
    inspector = inspect(conn)
    
    # Check and drop vector_store_tasks table and indexes
    if 'vector_store_tasks' in inspector.get_table_names():
        try:
            op.drop_index('ix_vector_store_tasks_parse_task_id', table_name='vector_store_tasks')
        except:
            pass
        try:
            op.drop_index('ix_vector_store_tasks_task_id', table_name='vector_store_tasks')
        except:
            pass
        op.drop_table('vector_store_tasks')
    
    # Check and drop parse_tasks table and indexes
    if 'parse_tasks' in inspector.get_table_names():
        try:
            op.drop_index('ix_parse_tasks_task_id', table_name='parse_tasks')
        except:
            pass
        op.drop_table('parse_tasks')
    
    # Check and drop user_sessions table and indexes
    if 'user_sessions' in inspector.get_table_names():
        try:
            op.drop_index('ix_user_sessions_token_jti', table_name='user_sessions')
        except:
            pass
        try:
            op.drop_index('ix_user_sessions_user_id', table_name='user_sessions')
        except:
            pass
        op.drop_table('user_sessions')
    # ### end Alembic commands ###
